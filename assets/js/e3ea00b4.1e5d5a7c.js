"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[699],{7537(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"gazebo/chapters/chapter3","title":"Chapter 3: Unity for High-Fidelity Interaction","description":"Using Unity for high-fidelity visualization and human-robot interaction simulation","source":"@site/docs/gazebo/chapters/chapter3.md","sourceDirName":"gazebo/chapters","slug":"/gazebo/chapters/chapter3","permalink":"/physical-ai-humanoid-robotics-book/docs/gazebo/chapters/chapter3","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Chapter 3: Unity for High-Fidelity Interaction","description":"Using Unity for high-fidelity visualization and human-robot interaction simulation","sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Sensor Simulation in Gazebo","permalink":"/physical-ai-humanoid-robotics-book/docs/gazebo/chapters/chapter2"},"next":{"title":"Chapter 4: Bridging Gazebo and Unity","permalink":"/physical-ai-humanoid-robotics-book/docs/gazebo/chapters/chapter4"}}');var o=i(4848),r=i(8453);const a={title:"Chapter 3: Unity for High-Fidelity Interaction",description:"Using Unity for high-fidelity visualization and human-robot interaction simulation",sidebar_position:7},s="Chapter 3: Unity for High-Fidelity Interaction",l={},c=[{value:"Introduction to Unity in Robotics",id:"introduction-to-unity-in-robotics",level:2},{value:"Unity Environment Setup for Robotics",id:"unity-environment-setup-for-robotics",level:2},{value:"Unity Installation and Configuration",id:"unity-installation-and-configuration",level:3},{value:"ROS Integration Setup",id:"ros-integration-setup",level:3},{value:"Project Structure for Robotics Simulation",id:"project-structure-for-robotics-simulation",level:3},{value:"Rendering Humanoid Robots with Realistic Materials",id:"rendering-humanoid-robots-with-realistic-materials",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Realistic Material Creation",id:"realistic-material-creation",level:3},{value:"Animation and Joint Movement",id:"animation-and-joint-movement",level:3},{value:"Human-Robot Interaction Simulation",id:"human-robot-interaction-simulation",level:2},{value:"UI and Interaction Systems",id:"ui-and-interaction-systems",level:3},{value:"Gesture Recognition and Input Systems",id:"gesture-recognition-and-input-systems",level:3},{value:"ROS 2 Integration in Unity",id:"ros-2-integration-in-unity",level:2},{value:"Message Publishing and Subscribing",id:"message-publishing-and-subscribing",level:3},{value:"Visualization of ROS Data",id:"visualization-of-ros-data",level:3},{value:"Unity Scene Architecture for Robotics",id:"unity-scene-architecture-for-robotics",level:2},{value:"Scene Organization",id:"scene-organization",level:3},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"Integration with Gazebo Data",id:"integration-with-gazebo-data",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-3-unity-for-high-fidelity-interaction",children:"Chapter 3: Unity for High-Fidelity Interaction"})}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-unity-in-robotics",children:"Introduction to Unity in Robotics"}),"\n",(0,o.jsx)(e.p,{children:"While Gazebo excels at physics simulation and sensor modeling, Unity provides unparalleled capabilities for high-fidelity rendering and human-robot interaction simulation. Unity's advanced graphics engine, intuitive development environment, and extensive asset ecosystem make it an ideal platform for creating visually compelling digital twins that enhance the realism and usability of robotics simulations."}),"\n",(0,o.jsx)(e.p,{children:"For humanoid robots, Unity's strength lies in creating immersive visualization environments that can help developers understand robot behavior, test interaction scenarios, and present robotics concepts to stakeholders. Unity complements Gazebo's physics simulation with high-quality visualization and interactive human-robot interfaces."}),"\n",(0,o.jsx)(e.h2,{id:"unity-environment-setup-for-robotics",children:"Unity Environment Setup for Robotics"}),"\n",(0,o.jsx)(e.h3,{id:"unity-installation-and-configuration",children:"Unity Installation and Configuration"}),"\n",(0,o.jsx)(e.p,{children:"Unity Hub provides a centralized way to manage Unity installations and projects. For robotics applications, we recommend using Unity 2022.3 LTS (Long Term Support) for stability and compatibility:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Install Unity Hub"}),": Download from the Unity website"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Install Unity Editor"}),": Select 2022.3 LTS version"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Install modules"}),": Include Visual Studio integration and required build targets"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Configure for robotics"}),": Set up project templates and asset repositories"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"ros-integration-setup",children:"ROS Integration Setup"}),"\n",(0,o.jsx)(e.p,{children:"The Unity ROS TCP Connector enables communication between Unity and ROS 2 systems. This bridge allows Unity to send and receive ROS messages, creating a seamless integration:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example Unity C# script for ROS connection\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing ROS2;\n\npublic class UnityROSBridge : MonoBehaviour\n{\n    private ROS2UnityComponent ros2;\n    private UDPBase udpBase;\n\n    [Header("ROS Connection Settings")]\n    public string rosMasterUrl = "127.0.0.1";\n    public int rosMasterPort = 11345;\n\n    void Start()\n    {\n        // Initialize ROS2 component\n        ros2 = GetComponent<ROS2UnityComponent>();\n        ros2.ROSConnectionSettings.protocol = ConnectionProtocol.TCP;\n        ros2.ROSConnectionSettings.node_name = "unity_robot_sim";\n\n        // Initialize UDP for sensor data (if needed)\n        udpBase = new UDPBase();\n        udpBase.Connect(rosMasterUrl, rosMasterPort);\n\n        // Start ROS connection\n        ros2.Initialize();\n\n        Debug.Log("ROS connection initialized");\n    }\n\n    void OnDestroy()\n    {\n        if (ros2 != null)\n        {\n            ros2.Shutdown();\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"project-structure-for-robotics-simulation",children:"Project Structure for Robotics Simulation"}),"\n",(0,o.jsx)(e.p,{children:"A well-organized Unity project structure enhances maintainability and collaboration:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"UnityRoboticsProject/\n\u251c\u2500\u2500 Assets/\n\u2502   \u251c\u2500\u2500 Scripts/           # C# scripts for robot control and ROS integration\n\u2502   \u251c\u2500\u2500 Models/            # 3D models for robots and environments\n\u2502   \u251c\u2500\u2500 Materials/         # Material definitions and textures\n\u2502   \u251c\u2500\u2500 Scenes/            # Unity scene files\n\u2502   \u251c\u2500\u2500 Prefabs/           # Reusable robot and environment components\n\u2502   \u251c\u2500\u2500 Plugins/           # Third-party plugins (ROS bridge, etc.)\n\u2502   \u2514\u2500\u2500 Resources/         # Runtime-loadable assets\n\u251c\u2500\u2500 ProjectSettings/       # Unity project configuration\n\u2514\u2500\u2500 Packages/              # Unity package dependencies\n"})}),"\n",(0,o.jsx)(e.h2,{id:"rendering-humanoid-robots-with-realistic-materials",children:"Rendering Humanoid Robots with Realistic Materials"}),"\n",(0,o.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,o.jsx)(e.p,{children:"Robot models created in CAD software or defined in URDF can be imported into Unity using several approaches:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Direct import"}),": Import STL, FBX, or OBJ files directly"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"URDF importer"}),": Use Unity's URDF Importer package for automatic conversion"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Custom import pipeline"}),": Create scripts to process URDF and generate Unity objects"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example script for importing and configuring robot parts\nusing UnityEngine;\n\npublic class RobotImporter : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public string robotName = "HumanoidRobot";\n    public Transform robotRoot;\n\n    [Header("Visual Configuration")]\n    public Material defaultMaterial;\n    public Material highlightMaterial;\n\n    void Start()\n    {\n        SetupRobotMaterials();\n        ConfigureRobotJoints();\n    }\n\n    void SetupRobotMaterials()\n    {\n        // Apply materials to robot parts\n        Renderer[] renderers = robotRoot.GetComponentsInChildren<Renderer>();\n\n        foreach (Renderer renderer in renderers)\n        {\n            // Apply default material if none exists\n            if (renderer.material == null)\n            {\n                renderer.material = defaultMaterial;\n            }\n\n            // Configure material properties for realism\n            ConfigureMaterial(renderer.material);\n        }\n    }\n\n    void ConfigureMaterial(Material material)\n    {\n        // Set realistic material properties\n        material.SetFloat("_Metallic", 0.2f);\n        material.SetFloat("_Smoothness", 0.5f);\n        material.EnableKeyword("_NORMALMAP");\n    }\n\n    void ConfigureRobotJoints()\n    {\n        // Configure Unity joints to match URDF joint limits\n        ConfigurableJoint[] joints = robotRoot.GetComponentsInChildren<ConfigurableJoint>();\n\n        foreach (ConfigurableJoint joint in joints)\n        {\n            ConfigureJointLimits(joint);\n        }\n    }\n\n    void ConfigureJointLimits(ConfigurableJoint joint)\n    {\n        // Example: Configure revolute joint limits\n        SoftJointLimit limit = joint.angularYLimit;\n        limit.limit = 90f; // Example: 90 degree limit\n        joint.angularYLimit = limit;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"realistic-material-creation",children:"Realistic Material Creation"}),"\n",(0,o.jsx)(e.p,{children:"Creating realistic materials enhances the visual fidelity of robot models:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Material configuration script for realistic robot appearance\nusing UnityEngine;\n\n[CreateAssetMenu(fileName = "RobotMaterialConfig", menuName = "Robotics/Material Config")]\npublic class RobotMaterialConfig : ScriptableObject\n{\n    [Header("Base Properties")]\n    public Color baseColor = Color.gray;\n    public float metallic = 0.1f;\n    public float smoothness = 0.5f;\n\n    [Header("Surface Details")]\n    public Texture2D normalMap;\n    public Texture2D roughnessMap;\n    public float surfaceScale = 1.0f;\n\n    [Header("Special Effects")]\n    public bool hasEmission = false;\n    public Color emissionColor = Color.black;\n    public float emissionIntensity = 1.0f;\n}\n\npublic class MaterialApplier : MonoBehaviour\n{\n    public RobotMaterialConfig materialConfig;\n    public Material robotMaterial;\n\n    void Start()\n    {\n        if (materialConfig != null)\n        {\n            ApplyMaterialConfig();\n        }\n    }\n\n    void ApplyMaterialConfig()\n    {\n        // Apply base properties\n        robotMaterial.SetColor("_BaseColor", materialConfig.baseColor);\n        robotMaterial.SetFloat("_Metallic", materialConfig.metallic);\n        robotMaterial.SetFloat("_Smoothness", materialConfig.smoothness);\n\n        // Apply textures\n        if (materialConfig.normalMap != null)\n        {\n            robotMaterial.SetTexture("_NormalMap", materialConfig.normalMap);\n        }\n\n        if (materialConfig.roughnessMap != null)\n        {\n            robotMaterial.SetTexture("_MetallicGlossMap", materialConfig.roughnessMap);\n        }\n\n        // Configure emission\n        if (materialConfig.hasEmission)\n        {\n            robotMaterial.EnableKeyword("_EMISSION");\n            robotMaterial.SetColor("_EmissionColor",\n                materialConfig.emissionColor * materialConfig.emissionIntensity);\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"animation-and-joint-movement",children:"Animation and Joint Movement"}),"\n",(0,o.jsx)(e.p,{children:"Animating robot joints in Unity provides visual feedback for robot movement:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Robot animation controller\nusing UnityEngine;\n\npublic class RobotAnimator : MonoBehaviour\n{\n    [Header("Joint Configuration")]\n    public Transform[] jointTransforms;\n    public ConfigurableJoint[] joints;\n\n    [Header("Animation Parameters")]\n    public float animationSpeed = 1.0f;\n    public AnimationCurve jointMovementCurve;\n\n    private float[] targetJointPositions;\n    private float[] currentJointPositions;\n\n    void Start()\n    {\n        InitializeJoints();\n    }\n\n    void InitializeJoints()\n    {\n        joints = GetComponentsInChildren<ConfigurableJoint>();\n        targetJointPositions = new float[joints.Length];\n        currentJointPositions = new float[joints.Length];\n\n        for (int i = 0; i < joints.Length; i++)\n        {\n            // Initialize with current positions\n            currentJointPositions[i] = GetJointPosition(joints[i]);\n            targetJointPositions[i] = currentJointPositions[i];\n        }\n    }\n\n    void Update()\n    {\n        AnimateJoints();\n    }\n\n    void AnimateJoints()\n    {\n        for (int i = 0; i < joints.Length; i++)\n        {\n            if (joints[i] != null)\n            {\n                // Smoothly interpolate to target position\n                currentJointPositions[i] = Mathf.Lerp(\n                    currentJointPositions[i],\n                    targetJointPositions[i],\n                    Time.deltaTime * animationSpeed\n                );\n\n                // Apply position to joint\n                SetJointPosition(joints[i], currentJointPositions[i]);\n            }\n        }\n    }\n\n    float GetJointPosition(ConfigurableJoint joint)\n    {\n        // Extract current joint position based on joint type\n        // This is a simplified example - actual implementation depends on joint configuration\n        return joint.transform.localEulerAngles.y;\n    }\n\n    void SetJointPosition(ConfigurableJoint joint, float position)\n    {\n        // Set joint to new position\n        // Actual implementation depends on joint configuration\n        joint.transform.localEulerAngles = new Vector3(0, position, 0);\n    }\n\n    // Public method to set target joint positions from external source (e.g., ROS)\n    public void SetTargetJointPositions(float[] positions)\n    {\n        for (int i = 0; i < Mathf.Min(targetJointPositions.Length, positions.Length); i++)\n        {\n            targetJointPositions[i] = positions[i];\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"human-robot-interaction-simulation",children:"Human-Robot Interaction Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"ui-and-interaction-systems",children:"UI and Interaction Systems"}),"\n",(0,o.jsx)(e.p,{children:"Creating intuitive interfaces for human-robot interaction in Unity:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Human-robot interaction interface\nusing UnityEngine;\nusing UnityEngine.UI;\nusing TMPro;\n\npublic class HumanRobotInterface : MonoBehaviour\n{\n    [Header("UI Elements")]\n    public Button moveForwardButton;\n    public Button moveBackwardButton;\n    public Button turnLeftButton;\n    public Button turnRightButton;\n    public Slider speedSlider;\n    public TextMeshProUGUI statusText;\n\n    [Header("Robot Control")]\n    public RobotController robotController;\n\n    void Start()\n    {\n        SetupUI();\n    }\n\n    void SetupUI()\n    {\n        // Setup button click events\n        if (moveForwardButton != null)\n            moveForwardButton.onClick.AddListener(() => SendCommand("forward"));\n\n        if (moveBackwardButton != null)\n            moveBackwardButton.onClick.AddListener(() => SendCommand("backward"));\n\n        if (turnLeftButton != null)\n            turnLeftButton.onClick.AddListener(() => SendCommand("turn_left"));\n\n        if (turnRightButton != null)\n            turnRightButton.onClick.AddListener(() => SendCommand("turn_right"));\n\n        // Setup speed slider\n        if (speedSlider != null)\n            speedSlider.onValueChanged.AddListener(OnSpeedChanged);\n\n        UpdateStatus("Ready for interaction");\n    }\n\n    void SendCommand(string command)\n    {\n        if (robotController != null)\n        {\n            robotController.ExecuteCommand(command, speedSlider.value);\n            UpdateStatus($"Command sent: {command} at speed {speedSlider.value:F1}");\n        }\n    }\n\n    void OnSpeedChanged(float speed)\n    {\n        if (robotController != null)\n        {\n            robotController.SetSpeed(speed);\n        }\n    }\n\n    void UpdateStatus(string message)\n    {\n        if (statusText != null)\n        {\n            statusText.text = message;\n        }\n    }\n}\n\n// Robot controller that handles commands\npublic class RobotController : MonoBehaviour\n{\n    [Header("Movement Configuration")]\n    public float maxSpeed = 2.0f;\n    public float rotationSpeed = 90.0f; // degrees per second\n\n    private float currentSpeed = 1.0f;\n\n    public void ExecuteCommand(string command, float speed)\n    {\n        switch (command)\n        {\n            case "forward":\n                MoveForward(speed);\n                break;\n            case "backward":\n                MoveBackward(speed);\n                break;\n            case "turn_left":\n                RotateLeft(speed);\n                break;\n            case "turn_right":\n                RotateRight(speed);\n                break;\n        }\n    }\n\n    public void SetSpeed(float speed)\n    {\n        currentSpeed = Mathf.Clamp(speed, 0.1f, 1.0f);\n    }\n\n    void MoveForward(float speed)\n    {\n        Vector3 movement = transform.forward * maxSpeed * speed * Time.deltaTime;\n        transform.position += movement;\n    }\n\n    void MoveBackward(float speed)\n    {\n        Vector3 movement = transform.forward * maxSpeed * speed * Time.deltaTime;\n        transform.position -= movement;\n    }\n\n    void RotateLeft(float speed)\n    {\n        transform.Rotate(Vector3.up, -rotationSpeed * speed * Time.deltaTime);\n    }\n\n    void RotateRight(float speed)\n    {\n        transform.Rotate(Vector3.up, rotationSpeed * speed * Time.deltaTime);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"gesture-recognition-and-input-systems",children:"Gesture Recognition and Input Systems"}),"\n",(0,o.jsx)(e.p,{children:"Implementing gesture recognition for natural interaction:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Gesture recognition system\nusing UnityEngine;\n\npublic class GestureRecognition : MonoBehaviour\n{\n    [Header("Gesture Detection")]\n    public float minGestureDistance = 0.1f;\n    public float maxGestureTime = 1.0f;\n\n    private Vector3 gestureStartPos;\n    private float gestureStartTime;\n    private bool isGestureActive = false;\n\n    void Update()\n    {\n        HandleMouseGestures();\n        HandleTouchGestures();\n    }\n\n    void HandleMouseGestures()\n    {\n        if (Input.GetMouseButtonDown(0))\n        {\n            StartGesture(Input.mousePosition);\n        }\n        else if (Input.GetMouseButtonUp(0))\n        {\n            EndGesture(Input.mousePosition);\n        }\n    }\n\n    void HandleTouchGestures()\n    {\n        if (Input.touchCount > 0)\n        {\n            Touch touch = Input.GetTouch(0);\n\n            if (touch.phase == TouchPhase.Began)\n            {\n                StartGesture(touch.position);\n            }\n            else if (touch.phase == TouchPhase.Ended)\n            {\n                EndGesture(touch.position);\n            }\n        }\n    }\n\n    void StartGesture(Vector3 startPos)\n    {\n        gestureStartPos = startPos;\n        gestureStartTime = Time.time;\n        isGestureActive = true;\n    }\n\n    void EndGesture(Vector3 endPos)\n    {\n        if (isGestureActive)\n        {\n            float gestureTime = Time.time - gestureStartTime;\n            Vector3 gestureVector = endPos - gestureStartPos;\n            float gestureDistance = gestureVector.magnitude;\n\n            if (gestureDistance >= minGestureDistance && gestureTime <= maxGestureTime)\n            {\n                RecognizeGesture(gestureVector, gestureDistance, gestureTime);\n            }\n\n            isGestureActive = false;\n        }\n    }\n\n    void RecognizeGesture(Vector3 gestureVector, float distance, float time)\n    {\n        // Normalize gesture vector for direction recognition\n        Vector2 direction = gestureVector.normalized;\n\n        // Determine gesture type based on direction\n        if (Mathf.Abs(direction.x) > Mathf.Abs(direction.y))\n        {\n            // Horizontal gesture\n            if (direction.x > 0.5f)\n            {\n                ExecuteGesture("swipe_right");\n            }\n            else if (direction.x < -0.5f)\n            {\n                ExecuteGesture("swipe_left");\n            }\n        }\n        else\n        {\n            // Vertical gesture\n            if (direction.y > 0.5f)\n            {\n                ExecuteGesture("swipe_up");\n            }\n            else if (direction.y < -0.5f)\n            {\n                ExecuteGesture("swipe_down");\n            }\n        }\n    }\n\n    void ExecuteGesture(string gestureName)\n    {\n        Debug.Log($"Gesture recognized: {gestureName}");\n\n        // Send gesture to robot controller via ROS\n        SendGestureToRobot(gestureName);\n    }\n\n    void SendGestureToRobot(string gesture)\n    {\n        // This would typically send a ROS message to the robot\n        // For example, publish to a gesture topic\n        Debug.Log($"Sending gesture {gesture} to robot");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"ros-2-integration-in-unity",children:"ROS 2 Integration in Unity"}),"\n",(0,o.jsx)(e.h3,{id:"message-publishing-and-subscribing",children:"Message Publishing and Subscribing"}),"\n",(0,o.jsx)(e.p,{children:"Integrating Unity with ROS 2 for bidirectional communication:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// ROS 2 message publisher for Unity\nusing UnityEngine;\nusing ROS2;\n\npublic class UnityROSPublisher : MonoBehaviour\n{\n    private ROS2UnityComponent ros2;\n    private Publisher<std_msgs.msg.String> statusPublisher;\n    private Publisher<geometry_msgs.msg.Twist> cmdVelPublisher;\n\n    [Header("ROS Topics")]\n    public string statusTopic = "/unity_robot_status";\n    public string cmdVelTopic = "/cmd_vel";\n\n    void Start()\n    {\n        ros2 = GetComponent<ROS2UnityComponent>();\n        ros2.Initialize();\n\n        // Initialize publishers\n        statusPublisher = ros2.CreatePublisher<std_msgs.msg.String>(statusTopic);\n        cmdVelPublisher = ros2.CreatePublisher<geometry_msgs.msg.Twist>(cmdVelTopic);\n\n        // Start publishing robot status\n        InvokeRepeating("PublishRobotStatus", 0.0f, 1.0f);\n    }\n\n    void PublishRobotStatus()\n    {\n        if (statusPublisher != null)\n        {\n            var statusMsg = new std_msgs.msg.String();\n            statusMsg.Data = $"Unity robot at position: {transform.position}";\n            statusPublisher.Publish(statusMsg);\n        }\n    }\n\n    public void PublishVelocityCommand(float linearX, float angularZ)\n    {\n        if (cmdVelPublisher != null)\n        {\n            var cmdMsg = new geometry_msgs.msg.Twist();\n            cmdMsg.Linear.X = linearX;\n            cmdMsg.Angular.Z = angularZ;\n            cmdVelPublisher.Publish(cmdMsg);\n        }\n    }\n}\n\n// ROS 2 message subscriber for Unity\nusing UnityEngine;\nusing ROS2;\n\npublic class UnityROSSubscriber : MonoBehaviour\n{\n    private ROS2UnityComponent ros2;\n    private Subscription<sensor_msgs.msg.LaserScan> lidarSubscriber;\n    private Subscription<sensor_msgs.msg.Imu> imuSubscriber;\n\n    [Header("Sensor Data")]\n    public float[] lidarRanges;\n    public Vector3 imuOrientation;\n\n    void Start()\n    {\n        ros2 = GetComponent<ROS2UnityComponent>();\n        ros2.Initialize();\n\n        // Initialize subscribers\n        lidarSubscriber = ros2.CreateSubscription<sensor_msgs.msg.LaserScan>(\n            "/robot/lidar/scan",\n            ProcessLidarData\n        );\n\n        imuSubscriber = ros2.CreateSubscription<sensor_msgs.msg.Imu>(\n            "/imu/data",\n            ProcessIMUData\n        );\n    }\n\n    void ProcessLidarData(ROS2Msg msg)\n    {\n        var lidarMsg = (sensor_msgs.msg.LaserScan)msg;\n        lidarRanges = new float[lidarMsg.Ranges.Length];\n\n        for (int i = 0; i < lidarMsg.Ranges.Length; i++)\n        {\n            lidarRanges[i] = lidarMsg.Ranges[i];\n        }\n    }\n\n    void ProcessIMUData(ROS2Msg msg)\n    {\n        var imuMsg = (sensor_msgs.msg.Imu)msg;\n        imuOrientation = new Vector3(\n            imuMsg.Orientation.X,\n            imuMsg.Orientation.Y,\n            imuMsg.Orientation.Z\n        );\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"visualization-of-ros-data",children:"Visualization of ROS Data"}),"\n",(0,o.jsx)(e.p,{children:"Visualizing ROS data within Unity enhances the simulation experience:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Visualize sensor data in Unity\nusing UnityEngine;\n\npublic class SensorVisualizer : MonoBehaviour\n{\n    [Header("Visualization Configuration")]\n    public UnityROSSubscriber sensorSubscriber;\n    public GameObject lidarPointPrefab;\n    public Material obstacleMaterial;\n    public float visualizationRange = 10.0f;\n\n    private GameObject[] lidarPoints;\n\n    void Start()\n    {\n        CreateLidarVisualization();\n    }\n\n    void Update()\n    {\n        UpdateLidarVisualization();\n    }\n\n    void CreateLidarVisualization()\n    {\n        if (sensorSubscriber.lidarRanges != null)\n        {\n            lidarPoints = new GameObject[sensorSubscriber.lidarRanges.Length];\n\n            for (int i = 0; i < sensorSubscriber.lidarRanges.Length; i++)\n            {\n                lidarPoints[i] = Instantiate(lidarPointPrefab);\n                lidarPoints[i].transform.SetParent(transform);\n                lidarPoints[i].SetActive(false);\n            }\n        }\n    }\n\n    void UpdateLidarVisualization()\n    {\n        if (sensorSubscriber.lidarRanges != null)\n        {\n            for (int i = 0; i < sensorSubscriber.lidarRanges.Length; i++)\n            {\n                float distance = sensorSubscriber.lidarRanges[i];\n\n                if (distance > 0 && distance < visualizationRange)\n                {\n                    // Calculate angle for this laser beam\n                    float angle = Mathf.Lerp(-60f, 60f, (float)i / sensorSubscriber.lidarRanges.Length);\n\n                    // Convert polar to Cartesian coordinates\n                    float x = distance * Mathf.Cos(angle * Mathf.Deg2Rad);\n                    float z = distance * Mathf.Sin(angle * Mathf.Deg2Rad);\n\n                    // Position the visualization point\n                    lidarPoints[i].transform.position = transform.position + new Vector3(x, 0.1f, z);\n                    lidarPoints[i].SetActive(true);\n\n                    // Change color based on distance\n                    Renderer renderer = lidarPoints[i].GetComponent<Renderer>();\n                    if (renderer != null)\n                    {\n                        float colorIntensity = 1.0f - (distance / visualizationRange);\n                        renderer.material.color = Color.Lerp(Color.red, Color.green, colorIntensity);\n                    }\n                }\n                else\n                {\n                    lidarPoints[i].SetActive(false);\n                }\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"unity-scene-architecture-for-robotics",children:"Unity Scene Architecture for Robotics"}),"\n",(0,o.jsx)(e.h3,{id:"scene-organization",children:"Scene Organization"}),"\n",(0,o.jsx)(e.p,{children:"Unity scenes for robotics applications follow a structured organization pattern:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Robotics Scene Hierarchy:\n\u251c\u2500\u2500 Environment/\n\u2502   \u251c\u2500\u2500 Ground/\n\u2502   \u251c\u2500\u2500 Obstacles/\n\u2502   \u2514\u2500\u2500 Lighting/\n\u251c\u2500\u2500 Robots/\n\u2502   \u251c\u2500\u2500 HumanoidRobot/\n\u2502   \u2502   \u251c\u2500\u2500 Base/\n\u2502   \u2502   \u251c\u2500\u2500 Torso/\n\u2502   \u2502   \u251c\u2500\u2500 Arms/\n\u2502   \u2502   \u2514\u2500\u2500 Legs/\n\u2502   \u2514\u2500\u2500 Sensors/\n\u2502       \u251c\u2500\u2500 LiDAR/\n\u2502       \u251c\u2500\u2500 Camera/\n\u2502       \u2514\u2500\u2500 IMU/\n\u251c\u2500\u2500 UI/\n\u2502   \u251c\u2500\u2500 ControlPanel/\n\u2502   \u2514\u2500\u2500 StatusDisplay/\n\u2514\u2500\u2500 Managers/\n    \u251c\u2500\u2500 ROSBridge/\n    \u251c\u2500\u2500 SceneController/\n    \u2514\u2500\u2500 PhysicsController/\n"})}),"\n",(0,o.jsx)(e.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,o.jsx)(e.p,{children:"High-fidelity rendering requires careful optimization to maintain performance:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Graphics optimization manager\nusing UnityEngine;\n\npublic class GraphicsOptimizer : MonoBehaviour\n{\n    [Header("Quality Settings")]\n    public int targetFrameRate = 60;\n    public LODGroup[] lodGroups;\n    public int maxVisibleObjects = 100;\n\n    [Header("Dynamic Optimization")]\n    public float optimizationInterval = 1.0f;\n\n    private float lastOptimizationTime;\n\n    void Start()\n    {\n        // Set target frame rate\n        Application.targetFrameRate = targetFrameRate;\n\n        // Initialize LOD groups\n        InitializeLODs();\n\n        lastOptimizationTime = Time.time;\n    }\n\n    void Update()\n    {\n        // Periodic optimization\n        if (Time.time - lastOptimizationTime > optimizationInterval)\n        {\n            PerformOptimization();\n            lastOptimizationTime = Time.time;\n        }\n    }\n\n    void InitializeLODs()\n    {\n        lodGroups = FindObjectsOfType<LODGroup>();\n    }\n\n    void PerformOptimization()\n    {\n        // Dynamic LOD adjustment based on performance\n        float currentFrameRate = 1.0f / Time.unscaledDeltaTime;\n\n        if (currentFrameRate < targetFrameRate * 0.8f)\n        {\n            // Reduce quality if frame rate is too low\n            ReduceLODQuality();\n        }\n        else if (currentFrameRate > targetFrameRate * 0.95f)\n        {\n            // Increase quality if frame rate is good\n            IncreaseLODQuality();\n        }\n    }\n\n    void ReduceLODQuality()\n    {\n        foreach (LODGroup lodGroup in lodGroups)\n        {\n            // Switch to lower LOD level\n            lodGroup.ForceLOD(1); // Use medium detail\n        }\n    }\n\n    void IncreaseLODQuality()\n    {\n        foreach (LODGroup lodGroup in lodGroups)\n        {\n            // Switch to higher LOD level\n            lodGroup.ForceLOD(0); // Use high detail\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"integration-with-gazebo-data",children:"Integration with Gazebo Data"}),"\n",(0,o.jsx)(e.p,{children:"Unity can receive and visualize data from Gazebo simulations:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Python script to send Gazebo data to Unity (bridge example)\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu\nimport socket\nimport json\n\nclass GazeboUnityBridge(Node):\n    def __init__(self):\n        super().__init__('gazebo_unity_bridge')\n\n        # Setup socket connection to Unity\n        self.unity_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.unity_socket.connect(('127.0.0.1', 5555))\n\n        # Subscribe to Gazebo sensor data\n        self.lidar_sub = self.create_subscription(\n            LaserScan, '/robot/lidar/scan', self.lidar_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, '/robot/imu/data', self.imu_callback, 10\n        )\n\n        self.get_logger().info('Gazebo-Unity bridge initialized')\n\n    def lidar_callback(self, msg):\n        \"\"\"Send LiDAR data to Unity\"\"\"\n        lidar_data = {\n            'type': 'lidar',\n            'ranges': list(msg.ranges),\n            'angle_min': msg.angle_min,\n            'angle_max': msg.angle_max,\n            'angle_increment': msg.angle_increment\n        }\n\n        try:\n            self.unity_socket.send(json.dumps(lidar_data).encode())\n        except Exception as e:\n            self.get_logger().error(f'Error sending lidar data: {e}')\n\n    def imu_callback(self, msg):\n        \"\"\"Send IMU data to Unity\"\"\"\n        imu_data = {\n            'type': 'imu',\n            'orientation': [msg.orientation.x, msg.orientation.y,\n                           msg.orientation.z, msg.orientation.w],\n            'angular_velocity': [msg.angular_velocity.x, msg.angular_velocity.y,\n                                msg.angular_velocity.z],\n            'linear_acceleration': [msg.linear_acceleration.x, msg.linear_acceleration.y,\n                                   msg.linear_acceleration.z]\n        }\n\n        try:\n            self.unity_socket.send(json.dumps(imu_data).encode())\n        except Exception as e:\n            self.get_logger().error(f'Error sending imu data: {e}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    bridge = GazeboUnityBridge()\n\n    try:\n        rclpy.spin(bridge)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        bridge.unity_socket.close()\n        bridge.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"This chapter has explored Unity's capabilities for high-fidelity rendering and human-robot interaction simulation. Unity complements Gazebo's physics simulation by providing:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Advanced graphics"}),": High-quality rendering for realistic visualization"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Interactive interfaces"}),": Intuitive human-robot interaction systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS integration"}),": Bidirectional communication with ROS 2 systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance optimization"}),": Techniques to maintain frame rates with complex scenes"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Unity's strength lies in creating visually compelling and interactive experiences that enhance the realism of robotics simulations. The integration with ROS 2 enables Unity to serve as a sophisticated visualization and interaction layer that can receive sensor data from physics simulations and send control commands back to the system."}),"\n",(0,o.jsx)(e.p,{children:"In the next chapter, we'll explore how to bridge Gazebo and Unity environments to create a comprehensive digital twin that combines the physics accuracy of Gazebo with the visual fidelity of Unity."})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>a,x:()=>s});var t=i(6540);const o={},r=t.createContext(o);function a(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);