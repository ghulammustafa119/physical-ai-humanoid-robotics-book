"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[318],{2092(e,n,a){a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"ros2/chapters/chapter3","title":"Chapter 3: Bridging Python AI Agents to ROS 2 Controllers","description":"Connecting AI agents to ROS 2 using rclpy for intelligent robot control","source":"@site/docs/ros2/chapters/chapter3.md","sourceDirName":"ros2/chapters","slug":"/ros2/chapters/chapter3","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2/chapters/chapter3","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3: Bridging Python AI Agents to ROS 2 Controllers","description":"Connecting AI agents to ROS 2 using rclpy for intelligent robot control","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: ROS 2 Communication Primitives","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2/chapters/chapter2"},"next":{"title":"Chapter 4: Modeling Humanoid Robots with URDF","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2/chapters/chapter4"}}');var s=a(4848),i=a(8453);const r={title:"Chapter 3: Bridging Python AI Agents to ROS 2 Controllers",description:"Connecting AI agents to ROS 2 using rclpy for intelligent robot control",sidebar_position:3},o="Chapter 3: Bridging Python AI Agents to ROS 2 Controllers",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"AI Agents in Robotics Context",id:"ai-agents-in-robotics-context",level:2},{value:"What are AI Agents in Robotics?",id:"what-are-ai-agents-in-robotics",level:3},{value:"Types of AI Agents for Robotics",id:"types-of-ai-agents-for-robotics",level:3},{value:"Role in Distributed Robot Cognition",id:"role-in-distributed-robot-cognition",level:3},{value:"rclpy: The Python Bridge to ROS 2",id:"rclpy-the-python-bridge-to-ros-2",level:2},{value:"Introduction to rclpy",id:"introduction-to-rclpy",level:3},{value:"Installation and Setup",id:"installation-and-setup",level:3},{value:"Basic Node Structure with rclpy",id:"basic-node-structure-with-rclpy",level:3},{value:"Translating High-Level Decisions to Robot Commands",id:"translating-high-level-decisions-to-robot-commands",level:2},{value:"Command Translation Pipeline",id:"command-translation-pipeline",level:3},{value:"Example: Goal-Based Navigation",id:"example-goal-based-navigation",level:3},{value:"Architectural Patterns for Agent-to-ROS Integration",id:"architectural-patterns-for-agent-to-ros-integration",level:2},{value:"Pattern 1: Direct Integration",id:"pattern-1-direct-integration",level:3},{value:"Pattern 2: Adapter Pattern",id:"pattern-2-adapter-pattern",level:3},{value:"Pattern 3: Service-Based Integration",id:"pattern-3-service-based-integration",level:3},{value:"Safety and Validation Considerations",id:"safety-and-validation-considerations",level:2},{value:"Command Validation",id:"command-validation",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Integration Example: Complete AI Agent",id:"integration-example-complete-ai-agent",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-3-bridging-python-ai-agents-to-ros-2-controllers",children:"Chapter 3: Bridging Python AI Agents to ROS 2 Controllers"})}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"The integration of AI agents with ROS 2 represents a critical bridge between high-level decision-making and low-level robot control. This chapter explores how Python-based AI agents can interface with ROS 2 systems using the rclpy client library, enabling intelligent robot behavior through distributed cognition."}),"\n",(0,s.jsx)(n.h2,{id:"ai-agents-in-robotics-context",children:"AI Agents in Robotics Context"}),"\n",(0,s.jsx)(n.h3,{id:"what-are-ai-agents-in-robotics",children:"What are AI Agents in Robotics?"}),"\n",(0,s.jsx)(n.p,{children:"An AI agent in robotics is a software component that perceives its environment, makes decisions based on that perception, and takes actions to achieve specific goals. In the ROS 2 ecosystem, AI agents typically:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Process high-level commands or goals from users"}),"\n",(0,s.jsx)(n.li,{children:"Plan complex behaviors and sequences of actions"}),"\n",(0,s.jsx)(n.li,{children:"Coordinate multiple robot subsystems"}),"\n",(0,s.jsx)(n.li,{children:"Adapt to changing environmental conditions"}),"\n",(0,s.jsx)(n.li,{children:"Learn from experience to improve performance"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"types-of-ai-agents-for-robotics",children:"Types of AI Agents for Robotics"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Rule-Based Agents"}),": Use predefined if-then logic to make decisions based on sensor inputs and internal state."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Learning-Based Agents"}),": Utilize machine learning models to make decisions based on patterns in data."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"LLM-Driven Agents"}),": Leverage Large Language Models for natural language understanding and complex reasoning."]}),"\n",(0,s.jsx)(n.h3,{id:"role-in-distributed-robot-cognition",children:"Role in Distributed Robot Cognition"}),"\n",(0,s.jsx)(n.p,{children:'AI agents serve as the "brain" in the distributed cognitive system that is a ROS 2-powered robot:'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Perception Processing"}),": Interpret sensor data and extract meaningful information"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Decision Making"}),": Choose appropriate actions based on current state and goals"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Behavior Coordination"}),": Manage multiple concurrent tasks and subsystems"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Human Interaction"}),": Translate human commands into robot actions"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"rclpy-the-python-bridge-to-ros-2",children:"rclpy: The Python Bridge to ROS 2"}),"\n",(0,s.jsx)(n.h3,{id:"introduction-to-rclpy",children:"Introduction to rclpy"}),"\n",(0,s.jsx)(n.p,{children:"rclpy is the Python client library for ROS 2, providing a Pythonic interface to ROS 2's core functionality. It allows Python applications to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create and manage ROS 2 nodes"}),"\n",(0,s.jsx)(n.li,{children:"Publish and subscribe to topics"}),"\n",(0,s.jsx)(n.li,{children:"Provide and call services"}),"\n",(0,s.jsx)(n.li,{children:"Execute and monitor actions"}),"\n",(0,s.jsx)(n.li,{children:"Access parameters and logging systems"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"installation-and-setup",children:"Installation and Setup"}),"\n",(0,s.jsx)(n.p,{children:"To use rclpy, ensure you have a ROS 2 environment installed (such as ROS 2 Humble Hawksbill). The basic setup requires:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Ensure ROS 2 environment is sourced\nsource /opt/ros/humble/setup.bash\n"})}),"\n",(0,s.jsx)(n.p,{children:"For Python development:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\n"})}),"\n",(0,s.jsx)(n.h3,{id:"basic-node-structure-with-rclpy",children:"Basic Node Structure with rclpy"}),"\n",(0,s.jsx)(n.p,{children:"Here's a foundational example of an AI agent node:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\n\nclass AIAgentNode(Node):\n    def __init__(self):\n        super().__init__('ai_agent_node')\n\n        # Create subscribers for sensor data\n        self.laser_subscriber = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.laser_callback,\n            10\n        )\n\n        # Create publisher for robot commands\n        self.cmd_vel_publisher = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10\n        )\n\n        # Create timer for decision-making loop\n        self.timer = self.create_timer(0.1, self.decision_loop)  # 10Hz\n\n        self.get_logger().info('AI Agent Node initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        self.closest_obstacle = min(msg.ranges)\n        self.get_logger().debug(f'Closest obstacle: {self.closest_obstacle:.2f}m')\n\n    def decision_loop(self):\n        \"\"\"Main AI decision-making loop\"\"\"\n        # Simple navigation logic\n        cmd = Twist()\n\n        if hasattr(self, 'closest_obstacle') and self.closest_obstacle > 1.0:\n            # Move forward if path is clear\n            cmd.linear.x = 0.5\n            cmd.angular.z = 0.0\n        else:\n            # Turn to avoid obstacles\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.5\n\n        self.cmd_vel_publisher.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = AIAgentNode()\n\n    try:\n        rclpy.spin(ai_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"translating-high-level-decisions-to-robot-commands",children:"Translating High-Level Decisions to Robot Commands"}),"\n",(0,s.jsx)(n.h3,{id:"command-translation-pipeline",children:"Command Translation Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"The process of converting AI decisions to robot-executable commands involves several steps:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Goal Interpretation"}),": Understanding high-level commands or objectives"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Behavior Planning"}),": Breaking down goals into sequences of actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Command Generation"}),": Creating specific ROS 2 messages for robot controllers"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Safety Validation"}),": Ensuring commands are safe before execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Execution Monitoring"}),": Tracking command execution and adjusting as needed"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-goal-based-navigation",children:"Example: Goal-Based Navigation"}),"\n",(0,s.jsx)(n.p,{children:"Here's how an AI agent might handle a navigation goal:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped\nfrom nav_msgs.msg import Path\nfrom std_msgs.msg import String\nfrom action_msgs.msg import GoalStatus\n\nclass NavigationAgentNode(Node):\n    def __init__(self):\n        super().__init__('navigation_agent')\n\n        # Publishers\n        self.goal_publisher = self.create_publisher(\n            PoseStamped,\n            '/goal_pose',\n            10\n        )\n\n        # Subscribers\n        self.status_subscriber = self.create_subscription(\n            String,\n            '/navigation_status',\n            self.status_callback,\n            10\n        )\n\n        # Service client for path planning\n        self.plan_client = self.create_client(\n            # Using a generic service type - in practice this would be a specific navigation service\n        )\n\n        self.current_goal = None\n        self.navigation_active = False\n\n        self.get_logger().info('Navigation Agent initialized')\n\n    def set_goal(self, x, y, theta=0.0):\n        \"\"\"Set a navigation goal for the robot\"\"\"\n        goal_msg = PoseStamped()\n        goal_msg.header.frame_id = 'map'\n        goal_msg.header.stamp = self.get_clock().now().to_msg()\n        goal_msg.pose.position.x = x\n        goal_msg.pose.position.y = y\n        # Set orientation based on theta\n        goal_msg.pose.orientation.z = 0.0\n        goal_msg.pose.orientation.w = 1.0\n\n        self.current_goal = goal_msg\n        self.goal_publisher.publish(goal_msg.pose)\n        self.navigation_active = True\n        self.get_logger().info(f'Navigation goal set: ({x}, {y})')\n\n    def status_callback(self, msg):\n        \"\"\"Handle navigation status updates\"\"\"\n        if msg.data == 'goal_reached':\n            self.navigation_active = False\n            self.get_logger().info('Navigation goal reached successfully')\n        elif msg.data == 'goal_failed':\n            self.navigation_active = False\n            self.get_logger().warn('Navigation goal failed')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    nav_agent = NavigationAgentNode()\n\n    # Example: Set a navigation goal\n    nav_agent.set_goal(5.0, 3.0)  # Navigate to (5.0, 3.0)\n\n    try:\n        rclpy.spin(nav_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        nav_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"architectural-patterns-for-agent-to-ros-integration",children:"Architectural Patterns for Agent-to-ROS Integration"}),"\n",(0,s.jsx)(n.h3,{id:"pattern-1-direct-integration",children:"Pattern 1: Direct Integration"}),"\n",(0,s.jsx)(n.p,{children:"The simplest pattern involves the AI agent directly creating a ROS 2 node and handling all communication:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Pros"}),": Simple, straightforward, minimal overhead\n",(0,s.jsx)(n.strong,{children:"Cons"}),": Tightly coupled, harder to test independently"]}),"\n",(0,s.jsx)(n.h3,{id:"pattern-2-adapter-pattern",children:"Pattern 2: Adapter Pattern"}),"\n",(0,s.jsx)(n.p,{children:"An adapter layer separates AI logic from ROS 2 communication:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class RobotAdapter:\n    """Adapter layer between AI agent and ROS 2"""\n\n    def __init__(self, node):\n        self.node = node\n        self.cmd_vel_publisher = node.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.laser_subscriber = node.create_subscription(\n            LaserScan, \'/scan\', self._laser_callback, 10\n        )\n        self.sensors = {}\n\n    def _laser_callback(self, msg):\n        self.sensors[\'laser\'] = msg\n\n    def move_robot(self, linear_vel, angular_vel):\n        """Send movement command to robot"""\n        cmd = Twist()\n        cmd.linear.x = linear_vel\n        cmd.angular.z = angular_vel\n        self.cmd_vel_publisher.publish(cmd)\n\n    def get_sensor_data(self, sensor_name):\n        """Get sensor data"""\n        return self.sensors.get(sensor_name)\n\nclass AIController:\n    """Pure AI logic, independent of ROS 2"""\n\n    def __init__(self, robot_adapter):\n        self.adapter = robot_adapter\n\n    def navigate_to_goal(self, goal_x, goal_y):\n        """Pure AI logic for navigation"""\n        current_data = self.adapter.get_sensor_data(\'laser\')\n        if current_data:\n            # Make decisions based on sensor data\n            if min(current_data.ranges) > 1.0:\n                self.adapter.move_robot(0.5, 0.0)  # Move forward\n            else:\n                self.adapter.move_robot(0.0, 0.5)  # Turn\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Pros"}),": Better separation of concerns, easier to test AI logic independently\n",(0,s.jsx)(n.strong,{children:"Cons"}),": Additional complexity, potential performance overhead"]}),"\n",(0,s.jsx)(n.h3,{id:"pattern-3-service-based-integration",children:"Pattern 3: Service-Based Integration"}),"\n",(0,s.jsx)(n.p,{children:"AI agent communicates through ROS 2 services:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class AIAgentService(Node):\n    """AI agent as a ROS 2 service provider"""\n\n    def __init__(self):\n        super().__init__(\'ai_agent_service\')\n\n        # Provide AI decision-making service\n        self.decision_service = self.create_service(\n            # Custom service type for AI decisions\n            # This would be defined in a .srv file\n        )\n\n        # Subscribe to sensor data\n        self.sensor_subscriber = self.create_subscription(\n            # Sensor message type\n        )\n\n        self.sensors = {}\n\n    def make_decision(self, request, response):\n        """Process AI decision request"""\n        # Use sensor data and request parameters to make decision\n        # Return appropriate response\n        pass\n'})}),"\n",(0,s.jsx)(n.h2,{id:"safety-and-validation-considerations",children:"Safety and Validation Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"command-validation",children:"Command Validation"}),"\n",(0,s.jsx)(n.p,{children:"All commands from AI agents should be validated before execution:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def validate_command(self, cmd):\n    """Validate robot commands for safety"""\n    # Check velocity limits\n    if abs(cmd.linear.x) > self.max_linear_vel:\n        cmd.linear.x = self.max_linear_vel if cmd.linear.x > 0 else -self.max_linear_vel\n\n    if abs(cmd.angular.z) > self.max_angular_vel:\n        cmd.angular.z = self.max_angular_vel if cmd.angular.z > 0 else -self.max_angular_vel\n\n    # Check for dangerous commands\n    if cmd.linear.x > 0 and self.obstacle_detected():\n        cmd.linear.x = 0.0  # Stop if obstacle ahead\n\n    return cmd\n'})}),"\n",(0,s.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(n.p,{children:"Proper error handling ensures robust operation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def safe_execute_command(self, cmd):\n    """Safely execute robot command with error handling"""\n    try:\n        validated_cmd = self.validate_command(cmd)\n        self.cmd_vel_publisher.publish(validated_cmd)\n    except Exception as e:\n        self.get_logger().error(f\'Error executing command: {e}\')\n        # Emergency stop\n        emergency_stop = Twist()\n        self.cmd_vel_publisher.publish(emergency_stop)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"integration-example-complete-ai-agent",children:"Integration Example: Complete AI Agent"}),"\n",(0,s.jsx)(n.p,{children:"Here's a complete example combining the concepts:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import String\nimport math\n\nclass CompleteAIAgent(Node):\n    def __init__(self):\n        super().__init__('complete_ai_agent')\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.status_pub = self.create_publisher(String, '/ai_status', 10)\n\n        # Subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan, '/scan', self.scan_callback, 10\n        )\n\n        # Parameters\n        self.declare_parameter('max_linear_vel', 0.5)\n        self.declare_parameter('max_angular_vel', 1.0)\n        self.declare_parameter('safety_distance', 0.5)\n\n        # Internal state\n        self.laser_data = None\n        self.goal = None\n        self.current_behavior = 'idle'\n\n        # Decision loop timer\n        self.timer = self.create_timer(0.1, self.decision_callback)\n\n        self.get_logger().info('Complete AI Agent initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        self.laser_data = msg\n\n    def set_goal(self, x, y):\n        \"\"\"Set navigation goal\"\"\"\n        self.goal = (x, y)\n        self.current_behavior = 'navigate'\n        self.get_logger().info(f'Set navigation goal to ({x}, {y})')\n\n    def decision_callback(self):\n        \"\"\"Main decision-making loop\"\"\"\n        if not self.laser_data:\n            return\n\n        cmd = Twist()\n\n        if self.current_behavior == 'navigate' and self.goal:\n            cmd = self.navigate_to_goal()\n        elif self.current_behavior == 'avoid_obstacles':\n            cmd = self.avoid_obstacles()\n        else:\n            cmd = self.idle_behavior()\n\n        # Validate and publish command\n        cmd = self.validate_command(cmd)\n        self.cmd_vel_pub.publish(cmd)\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f'Behavior: {self.current_behavior}'\n        self.status_pub.publish(status_msg)\n\n    def navigate_to_goal(self):\n        \"\"\"Navigation behavior implementation\"\"\"\n        cmd = Twist()\n\n        # Simple proportional navigation\n        if self.goal:\n            # This would require robot's current pose which we'd get from TF or odometry\n            # For this example, we'll use a simplified approach\n            if min(self.laser_data.ranges) > self.get_parameter('safety_distance').value:\n                cmd.linear.x = self.get_parameter('max_linear_vel').value\n            else:\n                cmd.angular.z = self.get_parameter('max_angular_vel').value\n\n        return cmd\n\n    def avoid_obstacles(self):\n        \"\"\"Obstacle avoidance behavior\"\"\"\n        cmd = Twist()\n\n        min_range = min(self.laser_data.ranges)\n        if min_range < self.get_parameter('safety_distance').value:\n            # Stop and turn\n            cmd.linear.x = 0.0\n            cmd.angular.z = self.get_parameter('max_angular_vel').value\n        else:\n            # Move forward\n            cmd.linear.x = self.get_parameter('max_linear_vel').value\n\n        return cmd\n\n    def idle_behavior(self):\n        \"\"\"Default idle behavior\"\"\"\n        return Twist()  # No movement\n\n    def validate_command(self, cmd):\n        \"\"\"Validate commands for safety\"\"\"\n        max_lin = self.get_parameter('max_linear_vel').value\n        max_ang = self.get_parameter('max_angular_vel').value\n\n        cmd.linear.x = max(min(cmd.linear.x, max_lin), -max_lin)\n        cmd.angular.z = max(min(cmd.angular.z, max_ang), -max_ang)\n\n        return cmd\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = CompleteAIAgent()\n\n    # Set an example goal\n    ai_agent.set_goal(5.0, 3.0)\n\n    try:\n        rclpy.spin(ai_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"This chapter has covered the essential concepts for bridging Python AI agents to ROS 2 controllers:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"AI agents serve as the cognitive layer in distributed robot systems"}),"\n",(0,s.jsx)(n.li,{children:"rclpy provides the Python interface to ROS 2 functionality"}),"\n",(0,s.jsx)(n.li,{children:"Various architectural patterns exist for integration, each with trade-offs"}),"\n",(0,s.jsx)(n.li,{children:"Safety and validation are crucial for reliable operation"}),"\n",(0,s.jsx)(n.li,{children:"Practical examples demonstrate the concepts in working code"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The next chapter will explore modeling humanoid robots with URDF, which provides the structural foundation for the AI agents to control."})]})}function g(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,a){a.d(n,{R:()=>r,x:()=>o});var t=a(6540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);