"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[875],{1124(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"isaac/chapters/chapter4","title":"Chapter 4: Bridging the AI Brain to ROS 2","description":"Python AI agents, ROS 2 integration, and closed-loop feedback for humanoid robots","source":"@site/docs/isaac/chapters/chapter4.md","sourceDirName":"isaac/chapters","slug":"/isaac/chapters/chapter4","permalink":"/physical-ai-humanoid-robotics-book/docs/isaac/chapters/chapter4","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"title":"Chapter 4: Bridging the AI Brain to ROS 2","description":"Python AI agents, ROS 2 integration, and closed-loop feedback for humanoid robots","sidebar_position":12},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Planning & Decision Making","permalink":"/physical-ai-humanoid-robotics-book/docs/isaac/chapters/chapter3"},"next":{"title":"Chapter 1: Introduction to VLA","permalink":"/physical-ai-humanoid-robotics-book/docs/vla/chapters/chapter1"}}');var a=t(4848),i=t(8453);const o={title:"Chapter 4: Bridging the AI Brain to ROS 2",description:"Python AI agents, ROS 2 integration, and closed-loop feedback for humanoid robots",sidebar_position:12},r="Chapter 4: Bridging the AI Brain to ROS 2",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Python AI Agents as ROS 2 Nodes",id:"python-ai-agents-as-ros-2-nodes",level:2},{value:"AI Agent Architecture",id:"ai-agent-architecture",level:3},{value:"AI Agent Responsibilities",id:"ai-agent-responsibilities",level:3},{value:"Node Lifecycle Management",id:"node-lifecycle-management",level:3},{value:"How Decisions Become ROS 2 Actions",id:"how-decisions-become-ros-2-actions",level:2},{value:"Decision Processing Pipeline",id:"decision-processing-pipeline",level:3},{value:"Command Types and Mapping",id:"command-types-and-mapping",level:3},{value:"Closed-Loop Feedback Explanation",id:"closed-loop-feedback-explanation",level:2},{value:"Feedback Loop Architecture",id:"feedback-loop-architecture",level:3},{value:"State Estimation and Monitoring",id:"state-estimation-and-monitoring",level:3},{value:"Adaptive Decision Making",id:"adaptive-decision-making",level:3},{value:"Performance Monitoring and Adjustment",id:"performance-monitoring-and-adjustment",level:3},{value:"Integration Patterns",id:"integration-patterns",level:2},{value:"Publisher-Subscriber Pattern",id:"publisher-subscriber-pattern",level:3},{value:"Service Calls",id:"service-calls",level:3},{value:"Action Interface Pattern",id:"action-interface-pattern",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-4-bridging-the-ai-brain-to-ros-2",children:"Chapter 4: Bridging the AI Brain to ROS 2"})}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(n.p,{children:"The final layer of the AI-robot brain is the bridge to ROS 2, where high-level decisions become concrete robot actions. This bridge translates the outputs of perception, planning, and decision-making systems into ROS 2 messages that control the physical robot. The bridge must handle the transition from abstract intelligence to concrete action while maintaining the closed-loop feedback that enables intelligent, adaptive behavior."}),"\n",(0,a.jsx)(n.p,{children:"This chapter explores how Python AI agents function as ROS 2 nodes, how decisions become ROS 2 actions, and how closed-loop feedback enables intelligent robot behavior. We'll examine the patterns and practices for integrating AI intelligence with the ROS 2 communication framework."}),"\n",(0,a.jsx)(n.h2,{id:"python-ai-agents-as-ros-2-nodes",children:"Python AI Agents as ROS 2 Nodes"}),"\n",(0,a.jsx)(n.p,{children:"AI agents in the robot brain are implemented as ROS 2 nodes, enabling them to participate in the ROS 2 communication ecosystem while maintaining their intelligent decision-making capabilities."}),"\n",(0,a.jsx)(n.h3,{id:"ai-agent-architecture",children:"AI Agent Architecture"}),"\n",(0,a.jsx)(n.p,{children:"Python AI agents follow a structured architecture that integrates intelligence with ROS 2 communication:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Float32\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom sensor_msgs.msg import LaserScan, Image, Imu\nfrom nav_msgs.msg import Odometry\nfrom builtin_interfaces.msg import Time\n\nclass AIBrainNode(Node):\n    """\n    AI Brain node that bridges high-level intelligence to ROS 2 control.\n    This node receives sensor data, makes decisions, and sends commands to the robot.\n    """\n\n    def __init__(self):\n        super().__init__(\'ai_brain_node\')\n\n        # Initialize perception, planning, and decision-making components\n        self.perception_system = PerceptionSystem()\n        self.planning_system = PlanningSystem()\n        self.decision_system = DecisionSystem()\n\n        # Initialize ROS 2 communication components\n        self.setup_publishers()\n        self.setup_subscribers()\n\n        # Initialize internal state\n        self.robot_state = {}\n        self.goals = []\n        self.active_plan = None\n\n        # Setup processing timer\n        self.processing_timer = self.create_timer(\n            0.1,  # Process at 10 Hz\n            self.ai_processing_loop\n        )\n\n        self.get_logger().info(\'AI Brain node initialized\')\n\n    def setup_publishers(self):\n        """Setup ROS 2 publishers for sending commands to the robot."""\n        # Publisher for robot movement commands\n        self.cmd_vel_publisher = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10\n        )\n\n        # Publisher for navigation goals\n        self.goal_publisher = self.create_publisher(\n            PoseStamped,\n            \'/goal_pose\',\n            10\n        )\n\n        # Publisher for robot status\n        self.status_publisher = self.create_publisher(\n            String,\n            \'/ai_brain/status\',\n            10\n        )\n\n        # Publisher for action commands\n        self.action_publisher = self.create_publisher(\n            String,\n            \'/ai_brain/action\',\n            10\n        )\n\n    def setup_subscribers(self):\n        """Setup ROS 2 subscribers for receiving sensor data."""\n        # Subscribe to sensor data\n        self.lidar_subscriber = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.lidar_callback,\n            10\n        )\n\n        self.camera_subscriber = self.create_subscription(\n            Image,\n            \'/camera/image_raw\',\n            self.camera_callback,\n            10\n        )\n\n        self.imu_subscriber = self.create_subscription(\n            Imu,\n            \'/imu/data\',\n            self.imu_callback,\n            10\n        )\n\n        self.odometry_subscriber = self.create_subscription(\n            Odometry,\n            \'/odom\',\n            self.odometry_callback,\n            10\n        )\n\n        # Subscribe to robot state updates\n        self.robot_state_subscriber = self.create_subscription(\n            String,\n            \'/robot/state\',\n            self.robot_state_callback,\n            10\n        )\n\n        # Subscribe to goals from higher-level systems\n        self.goal_subscriber = self.create_subscription(\n            PoseStamped,\n            \'/goal_pose\',\n            self.goal_callback,\n            10\n        )\n\n    def lidar_callback(self, msg):\n        """Process LiDAR sensor data."""\n        self.robot_state[\'lidar\'] = {\n            \'ranges\': list(msg.ranges),\n            \'intensities\': list(msg.intensities),\n            \'angle_min\': msg.angle_min,\n            \'angle_max\': msg.angle_max,\n            \'angle_increment\': msg.angle_increment\n        }\n\n    def camera_callback(self, msg):\n        """Process camera sensor data."""\n        self.robot_state[\'camera\'] = {\n            \'encoding\': msg.encoding,\n            \'height\': msg.height,\n            \'width\': msg.width,\n            \'data\': msg.data  # In practice, this would be processed further\n        }\n\n    def imu_callback(self, msg):\n        """Process IMU sensor data."""\n        self.robot_state[\'imu\'] = {\n            \'orientation\': [msg.orientation.x, msg.orientation.y, msg.orientation.z, msg.orientation.w],\n            \'angular_velocity\': [msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z],\n            \'linear_acceleration\': [msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z]\n        }\n\n    def odometry_callback(self, msg):\n        """Process odometry data."""\n        self.robot_state[\'odometry\'] = {\n            \'pose\': msg.pose.pose,\n            \'twist\': msg.twist.twist\n        }\n\n    def robot_state_callback(self, msg):\n        """Process robot state updates."""\n        self.robot_state[\'status\'] = msg.data\n\n    def goal_callback(self, msg):\n        """Process new goal requests."""\n        new_goal = {\n            \'position\': [msg.pose.position.x, msg.pose.position.y, msg.pose.position.z],\n            \'orientation\': [msg.pose.orientation.x, msg.pose.orientation.y, msg.pose.orientation.z, msg.pose.orientation.w],\n            \'timestamp\': msg.header.stamp\n        }\n        self.goals.append(new_goal)\n\n    def ai_processing_loop(self):\n        """Main AI processing loop that runs continuously."""\n        if not self.robot_state:\n            self.get_logger().debug(\'Waiting for sensor data...\')\n            return\n\n        try:\n            # 1. Update perception system with current sensor data\n            world_model = self.perception_system.update(self.robot_state)\n\n            # 2. Process goals and update planning system\n            if self.goals:\n                self.active_plan = self.planning_system.update_goals(self.goals, world_model)\n\n            # 3. Make decisions based on current state and plan\n            decision = self.decision_system.make_decision(\n                world_model=world_model,\n                active_plan=self.active_plan,\n                robot_state=self.robot_state\n            )\n\n            # 4. Execute decision by sending commands to robot\n            self.execute_decision(decision)\n\n            # 5. Publish status updates\n            self.publish_status(decision)\n\n        except Exception as e:\n            self.get_logger().error(f\'Error in AI processing loop: {e}\')\n            self.publish_error_status(str(e))\n\n    def execute_decision(self, decision):\n        """Execute AI decision by sending appropriate ROS 2 commands."""\n        if decision[\'type\'] == \'navigation\':\n            self.send_navigation_command(decision[\'params\'])\n        elif decision[\'type\'] == \'manipulation\':\n            self.send_manipulation_command(decision[\'params\'])\n        elif decision[\'type\'] == \'interaction\':\n            self.send_interaction_command(decision[\'params\'])\n        elif decision[\'type\'] == \'idle\':\n            self.send_idle_command()\n        else:\n            self.get_logger().warn(f\'Unknown decision type: {decision["type"]}\')\n\n    def send_navigation_command(self, params):\n        """Send navigation commands to robot."""\n        cmd = Twist()\n        cmd.linear.x = params.get(\'linear_velocity\', 0.0)\n        cmd.linear.y = params.get(\'linear_y_velocity\', 0.0)\n        cmd.linear.z = params.get(\'linear_z_velocity\', 0.0)\n        cmd.angular.x = params.get(\'angular_x_velocity\', 0.0)\n        cmd.angular.y = params.get(\'angular_y_velocity\', 0.0)\n        cmd.angular.z = params.get(\'angular_z_velocity\', 0.0)\n\n        self.cmd_vel_publisher.publish(cmd)\n\n    def send_manipulation_command(self, params):\n        """Send manipulation commands to robot."""\n        # This would publish to manipulation-specific topics\n        # For example, joint position commands or gripper control\n        action_msg = String()\n        action_msg.data = f\'manipulation:{params}\'\n        self.action_publisher.publish(action_msg)\n\n    def send_interaction_command(self, params):\n        """Send interaction commands to robot."""\n        # This could control speech, gestures, or other interactive behaviors\n        action_msg = String()\n        action_msg.data = f\'interaction:{params}\'\n        self.action_publisher.publish(action_msg)\n\n    def send_idle_command(self):\n        """Send idle/stop commands to robot."""\n        cmd = Twist()  # Zero velocities\n        self.cmd_vel_publisher.publish(cmd)\n\n    def publish_status(self, decision):\n        """Publish AI brain status."""\n        status_msg = String()\n        status_msg.data = f"Active: {decision[\'type\']}, Goals: {len(self.goals)}"\n        self.status_publisher.publish(status_msg)\n\n    def publish_error_status(self, error_msg):\n        """Publish error status."""\n        status_msg = String()\n        status_msg.data = f"ERROR: {error_msg}"\n        self.status_publisher.publish(status_msg)\n\n    def cleanup(self):\n        """Cleanup resources before shutdown."""\n        self.get_logger().info(\'Shutting down AI Brain node\')\n\n\nclass PerceptionSystem:\n    """Handles perception and world modeling."""\n\n    def __init__(self):\n        self.world_model = {}\n\n    def update(self, sensor_data):\n        """Update world model based on sensor data."""\n        # Process sensor data to create world understanding\n        # This is where perception algorithms would run\n\n        processed_data = {\n            \'objects\': self.detect_objects(sensor_data),\n            \'obstacles\': self.identify_obstacles(sensor_data),\n            \'free_space\': self.map_free_space(sensor_data),\n            \'robot_pose\': self.estimate_robot_pose(sensor_data)\n        }\n\n        self.world_model.update(processed_data)\n        return self.world_model\n\n    def detect_objects(self, sensor_data):\n        """Detect objects in the environment."""\n        # In practice, this would use computer vision algorithms\n        return []\n\n    def identify_obstacles(self, sensor_data):\n        """Identify obstacles for navigation."""\n        # Process LiDAR and other sensor data to find obstacles\n        return []\n\n    def map_free_space(self, sensor_data):\n        """Map free navigable space."""\n        # Create map of traversable areas\n        return []\n\n    def estimate_robot_pose(self, sensor_data):\n        """Estimate robot\'s current position and orientation."""\n        # Use odometry and other data to estimate pose\n        return {\'x\': 0.0, \'y\': 0.0, \'theta\': 0.0}\n\n\nclass PlanningSystem:\n    """Handles path and task planning."""\n\n    def __init__(self):\n        self.current_plan = None\n\n    def update_goals(self, goals, world_model):\n        """Update planning based on new goals and world model."""\n        if not goals:\n            return None\n\n        # Select the most relevant goal\n        active_goal = goals[0]  # Simple selection for example\n\n        # Plan path to goal\n        plan = self.create_plan(active_goal, world_model)\n\n        # Update internal state\n        self.current_plan = plan\n\n        return plan\n\n    def create_plan(self, goal, world_model):\n        """Create a plan to achieve the goal."""\n        # This would implement planning algorithms\n        # For example, A* for path planning, STRIPS for task planning\n\n        plan = {\n            \'goal\': goal,\n            \'path\': self.compute_path_to_goal(goal, world_model),\n            \'actions\': self.determine_required_actions(goal, world_model),\n            \'constraints\': self.identify_constraints(world_model)\n        }\n\n        return plan\n\n    def compute_path_to_goal(self, goal, world_model):\n        """Compute path to the goal."""\n        # Implement path planning algorithm\n        return []\n\n    def determine_required_actions(self, goal, world_model):\n        """Determine actions needed to achieve goal."""\n        # Plan sequence of actions\n        return []\n\n    def identify_constraints(self, world_model):\n        """Identify constraints for plan execution."""\n        # Consider obstacles, safety, etc.\n        return {}\n\n\nclass DecisionSystem:\n    """Makes decisions based on planning and perception."""\n\n    def __init__(self):\n        self.decision_policy = None  # Could be learned policy or rule-based\n\n    def make_decision(self, world_model, active_plan, robot_state):\n        """Make decision based on current information."""\n        if active_plan is None:\n            return {\n                \'type\': \'idle\',\n                \'params\': {},\n                \'confidence\': 1.0\n            }\n\n        # Determine what action to take based on plan\n        decision = self.select_action(world_model, active_plan, robot_state)\n\n        return decision\n\n    def select_action(self, world_model, active_plan, robot_state):\n        """Select appropriate action based on current state."""\n        # This could implement various decision-making approaches:\n        # - Rule-based reasoning\n        # - Utility-based decision making\n        # - Reinforcement learning policy\n        # - Hierarchical task network\n\n        # For this example, simple navigation decision\n        if \'path\' in active_plan and active_plan[\'path\']:\n            # Navigate along planned path\n            next_waypoint = active_plan[\'path\'][0] if active_plan[\'path\'] else None\n\n            if next_waypoint:\n                # Calculate navigation command\n                nav_command = self.calculate_navigation_to_waypoint(next_waypoint, robot_state)\n\n                return {\n                    \'type\': \'navigation\',\n                    \'params\': nav_command,\n                    \'confidence\': 0.9\n                }\n\n        # Default idle if no plan or waypoints\n        return {\n            \'type\': \'idle\',\n            \'params\': {},\n            \'confidence\': 1.0\n        }\n\n    def calculate_navigation_to_waypoint(self, waypoint, robot_state):\n        """Calculate navigation command to reach waypoint."""\n        # Simple proportional navigation controller\n        robot_pose = robot_state.get(\'odometry\', {}).get(\'pose\', {})\n\n        # Calculate desired velocity to reach waypoint\n        dx = waypoint[\'x\'] - robot_pose.get(\'position\', {}).get(\'x\', 0)\n        dy = waypoint[\'y\'] - robot_pose.get(\'position\', {}).get(\'y\', 0)\n\n        # Simple proportional control\n        linear_vel = min(0.5, (dx**2 + dy**2)**0.5)  # Scale with distance\n        angular_vel = 1.0 * (dy / (abs(dx) + 0.01))  # Simple heading correction\n\n        return {\n            \'linear_velocity\': linear_vel,\n            \'angular_z_velocity\': angular_vel\n        }\n\n\ndef main(args=None):\n    """Main entry point for the AI Brain node."""\n    rclpy.init(args=args)\n\n    ai_brain_node = AIBrainNode()\n\n    try:\n        rclpy.spin(ai_brain_node)\n    except KeyboardInterrupt:\n        ai_brain_node.get_logger().info(\'Interrupted, shutting down...\')\n    finally:\n        ai_brain_node.cleanup()\n        ai_brain_node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"ai-agent-responsibilities",children:"AI Agent Responsibilities"}),"\n",(0,a.jsx)(n.p,{children:"AI agents in this architecture have several key responsibilities:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor Data Integration"}),": Collect and process data from multiple sensors"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"World Modeling"}),": Create and maintain understanding of the environment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Goal Processing"}),": Interpret and prioritize goals from various sources"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Decision Making"}),": Determine appropriate actions based on current state"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Command Execution"}),": Send commands to robot control systems"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Status Reporting"}),": Provide feedback on AI brain state and decisions"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"node-lifecycle-management",children:"Node Lifecycle Management"}),"\n",(0,a.jsx)(n.p,{children:"AI agents follow standard ROS 2 node lifecycles:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Initialization"}),": Setup publishers, subscribers, and internal state"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Operation"}),": Continuous processing loop with sensor data and decision making"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Shutdown"}),": Cleanup resources and ensure safe robot state"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"how-decisions-become-ros-2-actions",children:"How Decisions Become ROS 2 Actions"}),"\n",(0,a.jsx)(n.p,{children:"The transformation from AI decisions to ROS 2 actions involves several steps that ensure safe and appropriate robot behavior."}),"\n",(0,a.jsx)(n.h3,{id:"decision-processing-pipeline",children:"Decision Processing Pipeline"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class DecisionProcessor:\n    """Process AI decisions into ROS 2 commands."""\n\n    def __init__(self, node):\n        self.node = node\n        self.safety_checker = SafetyChecker()\n        self.command_generator = CommandGenerator()\n\n    def process_decision(self, decision):\n        """Process AI decision and convert to ROS 2 commands."""\n        # 1. Validate decision safety\n        if not self.safety_checker.is_safe(decision):\n            self.node.get_logger().warn(\'Decision is unsafe, overriding...\')\n            return self.generate_safe_override()\n\n        # 2. Validate decision feasibility\n        if not self.is_feasible(decision):\n            self.node.get_logger().warn(\'Decision is infeasible, selecting alternative...\')\n            return self.generate_alternative_action(decision)\n\n        # 3. Generate appropriate ROS 2 commands\n        ros_commands = self.command_generator.generate_commands(decision)\n\n        # 4. Apply safety limits\n        safe_commands = self.apply_safety_limits(ros_commands)\n\n        # 5. Publish commands to robot\n        self.publish_commands(safe_commands)\n\n        return safe_commands\n\n    def is_feasible(self, decision):\n        """Check if decision is feasible."""\n        # Check if robot has capability to execute decision\n        # Check if environment allows execution\n        # Check if current state permits action\n        return True\n\n    def generate_safe_override(self):\n        """Generate safe override commands."""\n        # Stop robot or return to safe state\n        pass\n\n    def generate_alternative_action(self, original_decision):\n        """Generate alternative action when original is not feasible."""\n        # Find safe alternative to original decision\n        pass\n\n    def apply_safety_limits(self, commands):\n        """Apply safety limits to commands."""\n        # Limit velocities, accelerations, forces\n        # Ensure commands stay within safe operating ranges\n        pass\n\n    def publish_commands(self, commands):\n        """Publish commands to appropriate ROS 2 topics."""\n        # Send commands to robot control systems\n        pass\n\n\nclass SafetyChecker:\n    """Check if decisions are safe for robot and environment."""\n\n    def __init__(self):\n        self.safety_limits = {\n            \'velocity\': {\'linear\': 1.0, \'angular\': 1.0},  # m/s, rad/s\n            \'acceleration\': {\'linear\': 2.0, \'angular\': 2.0},  # m/s\xb2, rad/s\xb2\n            \'force\': 100.0,  # N\n            \'torque\': 50.0  # Nm\n        }\n\n    def is_safe(self, decision):\n        """Check if decision is safe."""\n        # Check velocity limits\n        if \'params\' in decision and \'linear_velocity\' in decision[\'params\']:\n            if abs(decision[\'params\'][\'linear_velocity\']) > self.safety_limits[\'velocity\'][\'linear\']:\n                return False\n\n        # Check for collision risks\n        if self.would_cause_collision(decision):\n            return False\n\n        # Check for stability risks\n        if self.would_compromise_stability(decision):\n            return False\n\n        return True\n\n    def would_cause_collision(self, decision):\n        """Check if decision would cause collision."""\n        # Analyze decision against current world model\n        # Check predicted robot path for obstacles\n        return False\n\n    def would_compromise_stability(self, decision):\n        """Check if decision would compromise robot stability."""\n        # Analyze decision against robot dynamics\n        # Check center of mass, support polygon, etc.\n        return False\n\n\nclass CommandGenerator:\n    """Generate ROS 2 commands from AI decisions."""\n\n    def __init__(self):\n        pass\n\n    def generate_commands(self, decision):\n        """Generate appropriate ROS 2 commands for decision."""\n        command_type = decision.get(\'type\', \'unknown\')\n\n        if command_type == \'navigation\':\n            return self.generate_navigation_commands(decision)\n        elif command_type == \'manipulation\':\n            return self.generate_manipulation_commands(decision)\n        elif command_type == \'interaction\':\n            return self.generate_interaction_commands(decision)\n        elif command_type == \'idle\':\n            return self.generate_idle_commands(decision)\n        else:\n            return self.generate_unknown_command(decision)\n\n    def generate_navigation_commands(self, decision):\n        """Generate navigation commands."""\n        params = decision.get(\'params\', {})\n\n        cmd = Twist()\n        cmd.linear.x = params.get(\'linear_velocity\', 0.0)\n        cmd.linear.y = params.get(\'linear_y_velocity\', 0.0)\n        cmd.linear.z = params.get(\'linear_z_velocity\', 0.0)\n        cmd.angular.x = params.get(\'angular_x_velocity\', 0.0)\n        cmd.angular.y = params.get(\'angular_y_velocity\', 0.0)\n        cmd.angular.z = params.get(\'angular_z_velocity\', 0.0)\n\n        return {\'cmd_vel\': cmd}\n\n    def generate_manipulation_commands(self, decision):\n        """Generate manipulation commands."""\n        # This would generate joint position, velocity, or effort commands\n        pass\n\n    def generate_interaction_commands(self, decision):\n        """Generate interaction commands."""\n        # This would generate speech, gesture, or display commands\n        pass\n\n    def generate_idle_commands(self, decision):\n        """Generate idle commands (stop robot)."""\n        cmd = Twist()  # Zero all velocities\n        return {\'cmd_vel\': cmd}\n\n    def generate_unknown_command(self, decision):\n        """Generate command for unknown decision type."""\n        # Default to safe idle command\n        return self.generate_idle_commands({\'type\': \'idle\'})\n'})}),"\n",(0,a.jsx)(n.h3,{id:"command-types-and-mapping",children:"Command Types and Mapping"}),"\n",(0,a.jsx)(n.p,{children:"Different decision types map to different ROS 2 command types:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Navigation decisions"})," \u2192 ",(0,a.jsx)(n.code,{children:"geometry_msgs/Twist"})," for movement control"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Manipulation decisions"})," \u2192 Joint commands or action goals"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Interaction decisions"})," \u2192 Speech, gesture, or UI commands"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Monitoring decisions"})," \u2192 Sensor configuration or data requests"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"closed-loop-feedback-explanation",children:"Closed-Loop Feedback Explanation"}),"\n",(0,a.jsx)(n.p,{children:"Closed-loop feedback is essential for intelligent robot behavior, enabling the AI brain to adapt its decisions based on outcomes and environmental changes."}),"\n",(0,a.jsx)(n.h3,{id:"feedback-loop-architecture",children:"Feedback Loop Architecture"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Perception \u2192 Planning \u2192 Decision \u2192 Action \u2192 Robot \u2192 Environment \u2192 Perception\n    \u2191                                                                 \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Feedback \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h3,{id:"state-estimation-and-monitoring",children:"State Estimation and Monitoring"}),"\n",(0,a.jsx)(n.p,{children:"The AI brain continuously monitors robot state and environment:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class StateEstimator:\n    """Estimate robot and environment state for feedback."""\n\n    def __init__(self):\n        self.robot_state_history = []\n        self.environment_state = {}\n        self.estimated_outcomes = {}\n\n    def update_state_estimate(self, sensor_data, command_sent, time_stamp):\n        """Update state estimate with new information."""\n        # Update robot state based on sensor feedback\n        self.update_robot_state(sensor_data, time_stamp)\n\n        # Update environment state based on observations\n        self.update_environment_state(sensor_data, time_stamp)\n\n        # Estimate outcome of recent commands\n        self.estimate_command_outcome(command_sent, sensor_data, time_stamp)\n\n    def update_robot_state(self, sensor_data, time_stamp):\n        """Update estimate of robot\'s current state."""\n        new_state = {\n            \'position\': self.estimate_position(sensor_data),\n            \'orientation\': self.estimate_orientation(sensor_data),\n            \'velocity\': self.estimate_velocity(sensor_data),\n            \'effort\': self.estimate_effort(sensor_data),\n            \'timestamp\': time_stamp\n        }\n\n        self.robot_state_history.append(new_state)\n\n        # Keep only recent history to manage memory\n        if len(self.robot_state_history) > 100:\n            self.robot_state_history.pop(0)\n\n    def update_environment_state(self, sensor_data, time_stamp):\n        """Update estimate of environment state."""\n        # Update map of environment\n        # Update locations of objects\n        # Update status of dynamic elements\n        pass\n\n    def estimate_command_outcome(self, command_sent, sensor_data, time_stamp):\n        """Estimate whether command achieved desired outcome."""\n        # Compare expected vs actual outcomes\n        # Update success/failure statistics\n        # Adjust future decision-making based on outcomes\n        pass\n\n    def get_current_state(self):\n        """Get current estimated state."""\n        if self.robot_state_history:\n            return {\n                \'robot\': self.robot_state_history[-1],\n                \'environment\': self.environment_state,\n                \'performance\': self.estimate_performance()\n            }\n        else:\n            return None\n\n    def estimate_performance(self):\n        """Estimate performance based on recent outcomes."""\n        # Calculate success rates\n        # Identify patterns in failures\n        # Assess efficiency of actions\n        pass\n'})}),"\n",(0,a.jsx)(n.h3,{id:"adaptive-decision-making",children:"Adaptive Decision Making"}),"\n",(0,a.jsx)(n.p,{children:"The feedback loop enables adaptive decision making:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class AdaptiveDecisionMaker:\n    """Make decisions that adapt based on feedback."""\n\n    def __init__(self):\n        self.performance_history = []\n        self.adaptation_rules = {}\n        self.learning_enabled = True\n\n    def make_adaptive_decision(self, current_state, original_plan, feedback):\n        """Make decision that adapts based on feedback."""\n        # Analyze recent performance\n        performance_analysis = self.analyze_recent_performance(feedback)\n\n        # Check if current approach is effective\n        if not performance_analysis[\'effective\']:\n            # Adapt decision-making strategy\n            adapted_plan = self.adapt_plan(original_plan, performance_analysis)\n            decision = self.make_decision_with_plan(adapted_plan, current_state)\n        else:\n            # Continue with current approach\n            decision = self.make_decision_with_plan(original_plan, current_state)\n\n        # Record decision for future learning\n        self.record_decision_outcome(decision, current_state)\n\n        return decision\n\n    def analyze_recent_performance(self, feedback):\n        """Analyze recent performance based on feedback."""\n        # Look for patterns in success/failure\n        # Identify environmental factors affecting performance\n        # Assess efficiency metrics\n        return {\n            \'effective\': True,  # Simplified for example\n            \'success_rate\': 0.8,\n            \'patterns\': [],\n            \'recommendations\': []\n        }\n\n    def adapt_plan(self, original_plan, performance_analysis):\n        """Adapt plan based on performance analysis."""\n        # Modify plan based on identified issues\n        # Adjust parameters for better performance\n        # Consider alternative strategies\n        adapted_plan = original_plan.copy()\n\n        # Example: if navigation is too slow, increase velocity limits\n        if performance_analysis.get(\'too_slow\'):\n            adapted_plan[\'velocity_limit\'] *= 1.2\n\n        return adapted_plan\n\n    def make_decision_with_plan(self, plan, current_state):\n        """Make decision following the given plan."""\n        # Implement decision-making logic that follows plan\n        pass\n\n    def record_decision_outcome(self, decision, state):\n        """Record decision and outcome for learning."""\n        outcome_record = {\n            \'decision\': decision,\n            \'state\': state,\n            \'timestamp\': self.get_current_time(),\n            \'expected_outcome\': decision.get(\'expected_outcome\'),\n            \'actual_outcome\': None  # Will be updated when feedback arrives\n        }\n\n        self.performance_history.append(outcome_record)\n\n        # Limit history size\n        if len(self.performance_history) > 1000:\n            self.performance_history.pop(0)\n\n    def get_current_time(self):\n        """Get current time for timestamping."""\n        import time\n        return time.time()\n\n    def learn_from_experience(self):\n        """Learn from recorded experiences."""\n        if not self.learning_enabled:\n            return\n\n        # Analyze patterns in successful/unsuccessful decisions\n        # Update decision-making parameters\n        # Improve future performance\n        pass\n'})}),"\n",(0,a.jsx)(n.h3,{id:"performance-monitoring-and-adjustment",children:"Performance Monitoring and Adjustment"}),"\n",(0,a.jsx)(n.p,{children:"Continuous monitoring enables performance optimization:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class PerformanceMonitor:\n    """Monitor AI brain performance and enable adjustments."""\n\n    def __init__(self):\n        self.metrics = {\n            \'decision_rate\': [],\n            \'success_rate\': [],\n            \'computation_time\': [],\n            \'resource_usage\': []\n        }\n        self.thresholds = {\n            \'min_success_rate\': 0.7,\n            \'max_computation_time\': 0.1,  # seconds\n            \'max_cpu_usage\': 80.0  # percent\n        }\n        self.adjustment_callbacks = []\n\n    def record_metric(self, metric_name, value, timestamp=None):\n        """Record performance metric."""\n        if metric_name not in self.metrics:\n            self.metrics[metric_name] = []\n\n        metric_entry = {\n            \'value\': value,\n            \'timestamp\': timestamp or self.get_current_time()\n        }\n\n        self.metrics[metric_name].append(metric_entry)\n\n        # Keep only recent metrics\n        self.trim_metrics(metric_name)\n\n        # Check if adjustment is needed\n        self.check_adjustment_needed(metric_name, value)\n\n    def trim_metrics(self, metric_name):\n        """Trim metrics history to manage memory."""\n        # Keep only last 1000 entries\n        if len(self.metrics[metric_name]) > 1000:\n            self.metrics[metric_name] = self.metrics[metric_name][-1000:]\n\n    def check_adjustment_needed(self, metric_name, value):\n        """Check if performance adjustment is needed."""\n        if metric_name == \'success_rate\':\n            if value < self.thresholds[\'min_success_rate\']:\n                self.trigger_adjustment(\'performance_degradation\')\n        elif metric_name == \'computation_time\':\n            if value > self.thresholds[\'max_computation_time\']:\n                self.trigger_adjustment(\'computation_overload\')\n\n    def trigger_adjustment(self, adjustment_type):\n        """Trigger performance adjustment."""\n        for callback in self.adjustment_callbacks:\n            callback(adjustment_type)\n\n    def add_adjustment_callback(self, callback):\n        """Add callback for performance adjustments."""\n        self.adjustment_callbacks.append(callback)\n\n    def get_performance_summary(self):\n        """Get summary of recent performance."""\n        summary = {}\n        for metric_name, values in self.metrics.items():\n            if values:\n                recent_values = [v[\'value\'] for v in values[-10:]]  # Last 10 values\n                summary[metric_name] = {\n                    \'current\': recent_values[-1] if recent_values else None,\n                    \'average\': sum(recent_values) / len(recent_values) if recent_values else None,\n                    \'trend\': self.calculate_trend(recent_values)\n                }\n\n        return summary\n\n    def calculate_trend(self, values):\n        """Calculate trend of recent values."""\n        if len(values) < 2:\n            return \'stable\'\n\n        # Simple trend calculation\n        if values[-1] > values[0]:\n            return \'increasing\'\n        elif values[-1] < values[0]:\n            return \'decreasing\'\n        else:\n            return \'stable\'\n\n    def get_current_time(self):\n        """Get current time for timestamping."""\n        import time\n        return time.time()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"integration-patterns",children:"Integration Patterns"}),"\n",(0,a.jsx)(n.h3,{id:"publisher-subscriber-pattern",children:"Publisher-Subscriber Pattern"}),"\n",(0,a.jsx)(n.p,{children:"The AI brain uses ROS 2's publisher-subscriber pattern extensively:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Subscribers"}),": Listen to sensor data, robot state, and commands"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Publishers"}),": Send robot commands, status updates, and AI brain state"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"service-calls",children:"Service Calls"}),"\n",(0,a.jsx)(n.p,{children:"For synchronous operations, the AI brain can use services:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class AIBrainWithServices(AIBrainNode):\n    """AI Brain node that also uses services for synchronous operations."""\n\n    def __init__(self):\n        super().__init__()\n\n        # Create service clients for synchronous operations\n        self.planning_service_client = self.create_client(\n            srv_type=GetPlan,  # Custom service type\n            srv_name=\'/planning_server/get_plan\'\n        )\n\n        self.kinematics_service_client = self.create_client(\n            srv_type=GetPositionIK,  # Inverse kinematics service\n            srv_name=\'/kinematics_service/get_ik\'\n        )\n\n    def request_plan_synchronously(self, start_pose, goal_pose):\n        """Request a plan synchronously using services."""\n        if not self.planning_service_client.service_is_ready():\n            self.get_logger().warn(\'Planning service not ready\')\n            return None\n\n        request = GetPlan.Request()\n        request.start = start_pose\n        request.goal = goal_pose\n\n        future = self.planning_service_client.call_async(request)\n\n        # Wait for response with timeout\n        rclpy.spin_until_future_complete(self, future, timeout_sec=5.0)\n\n        if future.done():\n            try:\n                response = future.result()\n                return response.plan\n            except Exception as e:\n                self.get_logger().error(f\'Service call failed: {e}\')\n                return None\n        else:\n            self.get_logger().warn(\'Service call timed out\')\n            return None\n'})}),"\n",(0,a.jsx)(n.h3,{id:"action-interface-pattern",children:"Action Interface Pattern"}),"\n",(0,a.jsx)(n.p,{children:"For long-running operations with feedback, the AI brain uses actions:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from rclpy.action import ActionClient\nfrom nav2_msgs.action import NavigateToPose\n\nclass AIBrainWithActions(AIBrainNode):\n    """AI Brain node that uses actions for long-running operations."""\n\n    def __init__(self):\n        super().__init__()\n\n        # Create action clients for long-running operations\n        self.navigation_action_client = ActionClient(\n            self,\n            NavigateToPose,\n            \'navigate_to_pose\'\n        )\n\n    def send_navigation_goal(self, goal_pose):\n        """Send navigation goal using action interface."""\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose = goal_pose\n\n        # Wait for action server\n        if not self.navigation_action_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'Navigation action server not available\')\n            return False\n\n        # Send goal asynchronously\n        self.navigation_action_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.navigation_feedback_callback,\n            goal_response_callback=self.navigation_goal_response_callback,\n            result_callback=self.navigation_result_callback\n        )\n\n        return True\n\n    def navigation_feedback_callback(self, feedback):\n        """Handle navigation feedback."""\n        self.get_logger().info(f\'Navigation progress: {feedback.feedback.distance_remaining:.2f}m remaining\')\n\n    def navigation_goal_response_callback(self, future):\n        """Handle navigation goal response."""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().warn(\'Navigation goal rejected\')\n            return\n\n        self.get_logger().info(\'Navigation goal accepted\')\n\n    def navigation_result_callback(self, future):\n        """Handle navigation result."""\n        result = future.result().result\n        self.get_logger().info(f\'Navigation completed: {result}\')\n'})}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"This chapter has explored how the AI brain bridges to ROS 2, connecting high-level intelligence to physical robot control. We've examined:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Python AI agents"})," as ROS 2 nodes that integrate intelligence with communication"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Decision-to-action transformation"})," that safely converts AI decisions to robot commands"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Closed-loop feedback systems"})," that enable adaptive, intelligent behavior"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Integration patterns"})," that connect AI intelligence with ROS 2 communication"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The bridge between AI intelligence and ROS 2 control is critical for creating autonomous robots that can operate intelligently in complex environments. This integration enables the perception-planning-decision-action cycle that characterizes intelligent robot behavior."}),"\n",(0,a.jsx)(n.p,{children:"The AI brain, perception systems, planning algorithms, and ROS 2 integration work together to create robots that can understand their environment, make intelligent decisions, and execute those decisions safely and effectively."}),"\n",(0,a.jsx)(n.p,{children:"This completes Module 3: AI-Robot Brain (NVIDIA Isaac\u2122), providing a foundation for understanding how artificial intelligence integrates with robotic control systems to create intelligent, autonomous humanoid robots."})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>o,x:()=>r});var s=t(6540);const a={},i=s.createContext(a);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);